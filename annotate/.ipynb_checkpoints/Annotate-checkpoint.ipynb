{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abertsch/git/ADEPTLab/annotate/example.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "doc_loc = FileChooser()\n",
    "output_loc = FileChooser()\n",
    "\n",
    "doc_loc.default_filename = \"example.txt\"\n",
    "output_loc.default_filename = \"output/\"\n",
    "\n",
    "print(doc_loc.default)\n",
    "\n",
    "#display(doc_loc)\n",
    "#display(output_loc)\n",
    "#print(doc_loc.selected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from colorama import Fore, Style\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "fps = {}\n",
    "valid_inputs = {\"0\": \"PERSON\", \"1\": \"NORP\", \"2\": \"LOC\", \"3\": \"FAC\",\n",
    "                \"4\": \"ORG\", \"5\": \"GPE\", \"6\": \"EVENT\", \"7\": \"QUANTITY\"}\n",
    "\n",
    "stanford_core_tags = {\"PERSON\": \"PERSON\", \"NORP\": \"O\", \"LOC\": \"LOCATION\", \"FAC\": \"O\",\n",
    "                       \"ORG\": \"O\", \"GPE\": \"LOCATION\", \"EVENT\": \"O\", \"QUANTITY\": \"O\"}\n",
    "\n",
    "stanford_ann = \"\"\n",
    "spacy_ann = []\n",
    "fileout = \"\"\n",
    "pos = 0\n",
    "\n",
    "def print_tags():\n",
    "    print(\"TAG OPTIONS: (press enter to leave untagged, b to go back)\")\n",
    "    print(\"0 people, including fictional\\t\\t4 companies, institutions, etc.\")\n",
    "    print(\"1 nationalities, religions\\t\\t5 countries, cities, states\")\n",
    "    print(\"2 mountains, rivers, etc.\\t\\t6 events--named hurricanes, etc\")\n",
    "    print(\"3 buildings, airports, etc.\\t\\t7 measurements (e.g. weight, distance)\")\n",
    "\n",
    "\n",
    "def annotate(fp):\n",
    "    file = fp.read()\n",
    "    words = file.split()\n",
    "    for i, word in enumerate(words):\n",
    "        get_tag(i, word, words)\n",
    "\n",
    "    fps[\"stanfordnlp-out\"].write(stanford_ann)\n",
    "    pickle.dump(spacy_ann, fps[\"spacy-out\"])\n",
    "    fps[\"rawtext-out\"].write(fileout)\n",
    "\n",
    "    for key in fps:\n",
    "        fps[key].close()\n",
    "\n",
    "\n",
    "\n",
    "def get_tag(i, word, words):\n",
    "    os.system('clear')\n",
    "    print_tag()\n",
    "    for j in range(i - 3, i):\n",
    "        if j >= 0:\n",
    "            print(words[j] + \" \", end=\"\")\n",
    "\n",
    "    print(f\"{Fore.GREEN} <<\" + word + f\">> {Style.RESET_ALL}\", end=\"\")\n",
    "\n",
    "    for k in range(i + 1, i + 4):\n",
    "        if k < len(words):\n",
    "            print(\" \" + words[k], end=\"\")\n",
    "\n",
    "    tag = input(\"\\n\\tTAG? \")\n",
    "    elif tag == \"\" or tag in valid_inputs:\n",
    "        write_annotation(word, tag)\n",
    "        print (\"\\033[A                             \\033[A\")\n",
    "        print (\"\\033[A                             \\033[A\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\n{Fore.RED}Sorry, not sure what that meant. Try again.{Style.RESET_ALL}\")\n",
    "        get_tag(i, word, words)\n",
    "\n",
    "    print()\n",
    "    return i\n",
    "\n",
    "def add_spacy_ann(word, tag):\n",
    "    word = word.strip(punctuation)\n",
    "    if(len(spacy_ann) != 0 and spacy_ann[-1][1] == pos and spacy_ann[-1][2] == valid_inputs[tag]):\n",
    "        spacy_ann.append((spacy_ann[-1][0], spacy_ann[-1][1] + 1 + len(word), valid_inputs[tag]))\n",
    "        spacy_ann.pop(-2)\n",
    "    else:\n",
    "        spacy_ann.append((pos + 1, pos + 1 + len(word), valid_inputs[tag]))\n",
    "\n",
    "\n",
    "def write_annotation(word, tag):\n",
    "    global fileout, stanford_ann, spacy_ann, pos\n",
    "\n",
    "    if tag == \"\":\n",
    "        fileout += \" \" + word\n",
    "        stanford_ann += word + \"\\t\" + \"O\" + \"\\n\"\n",
    "    else:\n",
    "        fileout += \" \" + word\n",
    "        stanford_ann += word + \"\\t\" + stanford_core_tags[valid_inputs[tag]] + \"\\n\"\n",
    "        add_spacy_ann(word, tag)\n",
    "\n",
    "    pos = pos + 1 + len(word)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = doc_loc.default\n",
    "    write_dir = output_loc.default\n",
    "\n",
    "    fps[\"input\"] = open(filename)\n",
    "    fps[\"stanfordnlp-out\"] = open(os.path.join(write_dir, filename.split(\"/\")[-1].split(\".\")[0]+ \"-stanfordnlp.tsv\"), \"w+\")\n",
    "    fps[\"spacy-out\"] = open(os.path.join(write_dir, filename.split(\"/\")[-1].split(\".\")[0]+ \"-spacy.pkl\"), \"wb+\")\n",
    "    fps[\"rawtext-out\"] = open(os.path.join(write_dir, filename.split(\"/\")[-1].split(\".\")[0]+ \"-rawtext.txt\"), \"w+\")\n",
    "    print_tags()\n",
    "    annotate(open(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "import ipyfilechooser\n",
    "print(ipyfilechooser.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
